{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3: Линейные модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <hr\\>\n",
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 8 апреля 2019, 06:00 <br\\>\n",
    "**Штраф за опоздание:** -2 балла после 06:00 8 апреля, -4 балла после 06:00 15 апреля, -6 баллов после 06:00 22 апреля  -8 баллов после 06:00 29 апреля.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла<br\\>\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания.\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw2.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст, если явно не указана такая возможность. В противном случае -1 балл\n",
    "<hr\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здравствуйте, уважаемые студенты! \n",
    "\n",
    "В этом задании мы будем реализовать линейные модели. Необходимо реализовать линейную и логистическую регрессии с L2 регуляризацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретическое введение\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Что почитать по теории ***\n",
    "\n",
    "Одна из лучших книг по ML $-$ \"Pattern Recognition and Machine Learning\" Bishop, Christopher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия решает задачу регрессии и оптимизирует функцию потерь MSE \n",
    "\n",
    "$$L(w) =  \\frac{1}{N}\\left[\\sum_i (y_i - a_i) ^ 2 \\right], $$ где $y_i$ $-$ целевая функция,  $a_i = a(x_i) =  \\langle\\,x_i,w\\rangle ,$ $-$ предсказание алгоритма на объекте $x_i$, $w$ $-$ вектор весов (размерности $D$), $x_i$ $-$ вектор признаков (такой же размерности $D$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия является линейным классификатором, который оптимизирует так называемый функционал log loss:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(w) = - \\frac{1}{N}\\left[\\sum_i y_i \\log a_i + ( 1 - y_i) \\log (1 - a_i) \\right],$$\n",
    "где  $y_i  \\in \\{0,1\\}$ $-$ метка класса, $a_i$ $-$ предсказание алгоритма на объекте $x_i$. Модель пытается предсказать апостериорую вероятность объекта принадлежать к классу \"1\":\n",
    "$$ p(y_i = 1 | x_i) = a(x_i) =  \\sigma( \\langle\\,x_i,w\\rangle ),$$\n",
    "$w$ $-$ вектор весов (размерности $D$), $x_i$ $-$ вектор признаков (такой же размерности $D$).\n",
    "\n",
    "Функция $\\sigma(x)$ $-$ нелинейная функция, пероводящее скалярное произведение объекта на веса в число $\\in (0,1)$ (мы же моделируем вероятность все-таки!)\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1 + \\exp(-x)}$$\n",
    "\n",
    "Если внимательно посмотреть на функцию потерь, то можно заметить, что в зависимости от правильного ответа алгоритм штрафуется или функцией $-\\log a_i$, или функцией $-\\log (1 - a_i)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто для решения проблем, которые так или иначе связаны с проблемой переобучения, в функционал качества добавляют слагаемое, которое называют ***регуляризацией***. Итоговый функционал для линейной регрессии тогда принимает вид:\n",
    "\n",
    "$$L(w) =  \\frac{1}{N}\\left[\\sum_i (y_i - a_i) ^ 2 \\right] + \\frac{1}{C}R(w) $$\n",
    "\n",
    "Для логистической: \n",
    "$$L(w) = - \\frac{1}{N}\\left[\\sum_i y_i \\log a_i + ( 1 - y_i) \\log (1 - a_i) \\right] +  \\frac{1}{C}R(w)$$\n",
    "\n",
    "Самое понятие регуляризации введено основателем ВМК академиком Тихоновым https://ru.wikipedia.org/wiki/Метод_регуляризации_Тихонова\n",
    "\n",
    "Идейно методика регуляризации заключается в следующем $-$ мы рассматриваем некорректно поставленную задачу (что это такое можно найти в интернете), для того чтобы сузить набор различных вариантов (лучшие из которых будут являться переобучением ) мы вводим дополнительные ограничения на множество искомых решений. На лекции Вы уже рассмотрели два варианта регуляризации.\n",
    "\n",
    "$L1$ регуляризация:\n",
    "$$R(w) = \\sum_{j=1}^{D}|w_j|$$\n",
    "$L2$ регуляризация:\n",
    "$$R(w) =  \\sum_{j=1}^{D}w_j^2$$\n",
    "\n",
    "С их помощью мы ограничиваем модель в  возможности выбора каких угодно весов минимизирующих наш лосс, модель уже не сможет подстроиться под данные как ей угодно. \n",
    "\n",
    "Вам нужно добавить соотвествущую Вашему варианту $L2$ регуляризацию.\n",
    "\n",
    "И так, мы поняли, какую функцию ошибки будем минимизировать, разобрались, как получить предсказания по объекту и обученным весам. Осталось разобраться, как получить оптимальные веса. Для этого нужно выбрать какой-то метод оптимизации.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный спуск является самым популярным алгоритмом обучения линейных моделей. В этом задании Вам предложат реализовать стохастический градиентный спуск или  мини-батч градиентный спуск (мини-батч на русский язык довольно сложно перевести, многие переводят это как \"пакетный\", но мне не кажется этот перевод удачным). Далее нам потребуется определение **эпохи**.\n",
    "Эпохой в SGD и MB-GD называется один проход по **всем** объектам в обучающей выборки.\n",
    "* В SGD градиент расчитывается по одному случайному объекту. Сам алгоритм выглядит примерно так:\n",
    "        1) Перемешать выборку\n",
    "        2) Посчитать градиент функции потерь на одном объекте (далее один объект тоже будем называть батчем)\n",
    "        3) Сделать шаг спуска\n",
    "        4) Повторять 2) и 3) пока не пройдет максимальное число эпох.\n",
    "* В Mini Batch SGD - по подвыборке объектов. Сам алгоритм выглядит примерно так::\n",
    "        1) Перемешать выборку, выбрать размер мини-батча (от 1 до размера выборки)\n",
    "        2) Почитать градиент функции потерь по мини-батчу (не забыть поделить на  число объектов в мини-батче)\n",
    "        3) Сделать шаг спуска\n",
    "        4) Повторять 2) и 3) пока не пройдет максимальное число эпох.\n",
    "* Для отладки алгоритма реализуйте возможность  вывода средней ошибки на обучении модели по объектам (мини-батчам). После шага градиентного спуска посчитайте значение ошибки на объекте (или мини-батче), а затем усредните, например, по ста шагам. Если обучение проходит корректно, то мы должны увидеть, что каждые 100 шагов функция потерь уменьшается. \n",
    "* Правило останова - максимальное количество эпох\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретические вопросы (2 балла)\n",
    "В этой части Вам будут предложены теоретичские вопросы и задачи по теме. Вы, конечно, можете списать их у своего товарища или найти решение в интернете, но учтите, что они обязательно войдут в теоретический коллоквиум. Лучше разобраться в теме сейчас и успешно ответить на коллоквиуме, чем списать, не разобравшись в материале, и быть терзаемым совестью. \n",
    "\n",
    "\n",
    "Формулы надо оформлять в формате **LaTeX**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 1. Градиент для линейной регрессии.\n",
    "* Выпишите формулу обновления весов для линейной регрессии с L2 регуляризацией для мини-батч градиентого спуска размера $n$:\n",
    "\n",
    "$$ w_{new} = w_{old} - ... $$\n",
    "\n",
    " Отнеситесь к этому пункту максимально серьезно, это Вам нужно будет реализовать в задании.\n",
    " \n",
    "Проанализруйте итоговую формулу градиента - как  интуитивно можно  описать, чему равен градиент?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Q(w)=\\frac{1}{N}[\\sum_{i}(y_i - a_i)^2] + \\frac{1}{C}\\sum_{j=1}^D w_j^2 $$\n",
    "\n",
    "$$ w_{new} = w_{old} - \\alpha grad_w Q(w) $$\n",
    "\n",
    "$$ grad_wQ(w) = \\frac{2}{N}[\\sum_{i}X_i(a_i-y_i)] + \\frac{2}{C}w $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 2. Градиент для логистической регрессии.\n",
    "* Выпишите формулу обновления весов для логистической регрессии с L2 регуляризацией  для мини-батч градиентого спуска размера $n$:\n",
    "\n",
    "$$ w_{new} = w_{old} - ... $$\n",
    "\n",
    " Отнеситесь к этому пункту максимально серьезно, это Вам нужно будет реализовать в задании.\n",
    " \n",
    "Проанализруйте итоговую формулу градиента - как  интуитивно можно  описать, чему равен градиент? Как соотносится этот градиент с градиентом, возникающий в задаче линейной регрессии?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\sigma(x) = \\frac{x}{1+exp(-(x,w)}$$\n",
    "\n",
    "$$ w_{new} = w_{old} - \\alpha[\\frac{1}{N}\\sum_{i}^N (\\sigma(x_i)-y_i) +  \\frac{2}{C}w]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 3. Точное решение линейной регрессии\n",
    "\n",
    "На лекции было показано, что точное решение линейной регрессии имеет вид $w = (X^TX)^{-1}X^TY $. \n",
    "* Покажите, что это действительно является точкой минимума в случае, если матрица X имеет строк не меньше, чем столбцов и имеет полный ранг. Подсказка: посчитайте Гессиан и покажите, что в этом случае он положительно определен. \n",
    "* Выпишите точное решение для модели с $L2$ регуляризацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ 2) w = (X^TX + \\frac{1}{C}I)X^Ty$$\n",
    "\n",
    "$$ 1) Q(w) = ||y - Xw||^2$$\n",
    "\n",
    "$$ (y - X(X^TX)^{-1}X^Ty) = A$$\n",
    "\n",
    "$$ (X^Ty - X^TX(X^TX)^{-1}X^Ty) = X^TA=0$$\n",
    "\n",
    "$$ A = 0$$\n",
    "\n",
    "Сл-но, это минимум, так как квадрат - число неотрицательное."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 4.  Предсказываем вероятности.\n",
    "\n",
    "Когда говорят о логистической регрессии, произносят фразу, что она \"предсказывает вероятности положительного класса\". Давайте разберемся, что же за этим стоит. Посчитаем математическое ожидание функции потерь и проверим, что предсказание алгоритма, оптимизирующее это мат. ожидание, будет являться вероятностью положительного класса. \n",
    "\n",
    "И так, функция потерь на объекте $x_i$, который имеет метку $y_i \\in \\{0,1\\}$  для предсказания $a(x_i)$ равна:\n",
    "$$L(y_i, b) =-[y_i == 1] \\log a(x_i)  - [y_i == 0] \\log(1 - a(x_i)) $$\n",
    "\n",
    "Где $[]$ означает индикатор $-$ он равен единице, если значение внутри него истинно, иначе он равен нулю. Тогда мат. ожидание при условии конкретного $x_i$  по определение мат. ожидания дискретной случайной величины:\n",
    "$$E(L | x_i) = -p(y_i = 1 |x_i ) \\log a(x_i)  - p(y_i = 0 | x_i) \\log( 1 - a(x_i))$$\n",
    "* Докажите, что значение $a(x_i)$, минимизирующее данное мат. ожидание, в точности равно $p(y_i = 1 |x_i)$, то есть равно вероятности положительного класса.\n",
    "\n",
    "Подсказка: возможно, придется воспользоваться, что  $p(y_i = 1 | x_i) + p(y_i = 0 | x_i) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\ Продиффиренцируем \\ уравнение,\\ задающее\\ мат \\ ожидание $$\n",
    "\n",
    "$$ p_1 = p(y_i == 1|x_i), \\ p_0 = p(y_i == 0|x_i)$$\n",
    "\n",
    "$$ \\frac{-p_1}{a(x_i)} + \\frac{p_0}{1-a(x_i)} = 0$$\n",
    "\n",
    "$$ a(x_i) = \\frac{p_1}{p_1+p_0} = p_1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Реализация линейной модели (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Зачем нужны батчи?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как Вы могли заметить из теоретического введения, что в случае SGD, что в случа mini-batch GD,  на каждой итерации обновление весов  происходит только по небольшой части данных (1 пример в случае SGD, batch примеров в случае mini-batch). То есть для каждой итерации нам *** не нужна вся выборка***. Мы можем просто итерироваться по выборке, беря батч нужного размера (далее 1 объект тоже будем называть батчом).\n",
    "\n",
    "Легко заметить, что в этом случае нам не нужно загружать все данные в оперативную память, достаточно просто считать батч с диска, обновить веса, считать диска другой батч и так далее. В целях упрощения домашней работы, прямо с диска  мы считывать не будем, будем работать с обычными numpy array. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Немножко про генераторы в Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея считывания данных кусками удачно ложится на так называемые ***генераторы*** из языка Python. В данной работе Вам предлагается не только разобраться с логистической регрессией, но  и познакомиться с таким важным элементом языка.  При желании Вы можете убрать весь код, связанный с генераторами, и реализовать логистическую регрессию и без них, ***штрафоваться это никак не будет***. Главное, чтобы сама модель была реализована правильно, и все пункты были выполнены. \n",
    "\n",
    "Подробнее можно почитать вот тут https://anandology.com/python-practice-book/iterators.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К генератору стоит относиться просто как к функции, которая порождает не один объект, а целую последовательность объектов. Новое значение из последовательности генерируется с помощью ключевого слова ***yield***. Ниже Вы можете насладиться  генератором чисел Фибоначчи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fib(max_iter=4):\n",
    "    a, b = 0, 1\n",
    "    iter_num = 0\n",
    "    while 1:\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "        iter_num += 1\n",
    "        if iter_num == max_iter:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так можно сгенерировать последовательность Фибоначчи. \n",
    "\n",
    "Заметьте, что к генераторам можно применять некоторые стандартные функции из Python, например enumerate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n"
     ]
    }
   ],
   "source": [
    "new_generator = fib()\n",
    "for j, fib_val in enumerate(new_generator):\n",
    "    print (\"Fib num: \" + str(j) + \" fib values: \" + str(fib_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пересоздавая объект, можно сколько угодно раз генерировать заново последовательность. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n",
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n",
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 3):\n",
    "    new_generator = fib()\n",
    "    for j, fib_val in enumerate(new_generator):\n",
    "        print (\"Fib num: \" + str(j) + \" fib values: \" + str(fib_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот так уже нельзя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n"
     ]
    }
   ],
   "source": [
    "new_generator = fib()\n",
    "for i in range(0, 3):\n",
    "    for j, fib_val in enumerate(new_generator):\n",
    "        print (\"Fib num: \" + str(j) + \" fib values: \" + str(fib_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Концепция крайне удобная для обучения  моделей $-$ у Вас есть некий источник данных, который Вам выдает их кусками, и Вам совершенно все равно откуда он их берет. Под ним может скрывать как массив в оперативной памяти, как файл на жестком диске, так и SQL база данных. Вы сами данные никуда не сохраняете, оперативную память экономите."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если Вам понравилась идея с генераторами, то Вы можете реализовать свой, используя прототип batch_generator. В нем Вам нужно выдавать батчи признаков и ответов для каждой новой итерации спуска. Если не понравилась идея, то можете реализовывать SGD или mini-batch GD без генераторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import datasets\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, shuffle_flag=True, batch_size=1):\n",
    "    \"\"\"\n",
    "    Гератор новых батчей для обучения\n",
    "    X          - матрица объекты-признаки\n",
    "    y_batch    - вектор ответов\n",
    "    shuffle    - нужно ли случайно перемешивать выборку\n",
    "    batch_size - размер батча ( 1 это SGD, > 1 mini-batch GD)\n",
    "    Генерирует подвыборку для итерации спуска (X_batch, y_batch)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_batch = np.zeros((batch_size, X.shape[1]))\n",
    "    y_batch = np.zeros((batch_size))\n",
    "    if shuffle_flag:\n",
    "            X, y = shuffle(X, y)\n",
    "    for i in range(0, X.shape[0] - batch_size, batch_size ):           \n",
    "        X_batch = [np.concatenate((X[j],[1])) for j in range(i,i + batch_size)]\n",
    "        y_batch = [y[j] for j in range(i,i + batch_size)]\n",
    "        yield (X_batch, y_batch)\n",
    "\n",
    "# Теперь можно сделать генератор по данным ()\n",
    "#  my_batch_generator = batch_generator(X, y, shuffle=True, batch_size=1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%pycodestyle\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Вычисляем значение сигмоида.\n",
    "    X - выход линейной модели\n",
    "    \"\"\"\n",
    "    sigm_value_x = (1 + np.exp(-x)) ** -1\n",
    "    return sigm_value_x\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "class MySGDClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, batch_generator, C=100, alpha=0.01, max_epoch=10, model_type='lin_reg', batch_size=1):\n",
    "        \"\"\"\n",
    "        batch_generator -- функция генератор, которой будем создавать батчи\n",
    "        C - коэф. регуляризации\n",
    "        alpha - скорость спуска\n",
    "        max_epoch - максимальное количество эпох\n",
    "        model_type - тим модели, lin_reg или log_reg\n",
    "        \"\"\"\n",
    "\n",
    "        self.C = C\n",
    "        self.alpha = alpha\n",
    "        self.max_epoch = max_epoch\n",
    "        self.batch_generator = batch_generator\n",
    "        self.errors_log = {'iter': [], 'loss': []}\n",
    "        self.model_type = model_type\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def calc_loss(self, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Считаем функцию потерь по батчу \n",
    "        X_batch - матрица объекты-признаки по батчу\n",
    "        y_batch - вектор ответов по батчу\n",
    "        Не забудте тип модели (линейная или логистическая регрессия)!\n",
    "        \"\"\"\n",
    "        N = len(y_batch)\n",
    "        loss = 0\n",
    "        if self.model_type == 'lin_reg':\n",
    "            loss = np.sum([(y_batch[i] - np.dot(X_batch[i], self.weights)) ** 2 for i in range(N)]) / N\n",
    "            loss += np.sum(self.weights ** 2) / self.C\n",
    "\n",
    "        if self.model_type == 'log_reg':\n",
    "            y_batch = np.array(y_batch)\n",
    "            sigm = sigmoid(np.dot(X_batch, self.weights))\n",
    "            loss = -np.sum(y_batch * np.log(sigm) + (1 - y_batch) * np.log(1 - sigm))\n",
    "            loss /= N\n",
    "            loss += np.sum(self.weights ** 2) / self.C\n",
    "        return loss\n",
    "\n",
    "    def calc_loss_grad(self, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Считаем  градиент функции потерь по батчу (то что Вы вывели в задании 1)\n",
    "        X_batch - матрица объекты-признаки по батчу\n",
    "        y_batch - вектор ответов по батчу\n",
    "        Не забудте тип модели (линейная или логистическая регрессия)!\n",
    "        \"\"\"\n",
    "        N = len(y_batch)\n",
    "        a = np.array([np.dot(X_batch[i], self.weights) for i in range(N)])\n",
    "        loss_grad = np.zeros((len(self.weights)))\n",
    "        if self.model_type == 'lin_reg':\n",
    "            loss_grad = np.sum([(a[i] - y_batch[i]) * X_batch[i] for i in range(N)], axis=0) * 2 / N\n",
    "            loss_grad += 2 / self.C * self.weights\n",
    "        if self.model_type == 'log_reg':\n",
    "            loss_grad = np.dot(sigmoid(np.dot(X_batch, self.weights)) - y_batch, X_batch) / N\n",
    "            loss_grad += 2 * self.weights / self.C\n",
    "        return loss_grad\n",
    "\n",
    "    def update_weights(self, new_grad):\n",
    "        \"\"\"\n",
    "        Обновляем вектор весов\n",
    "        new_grad - градиент по батчу\n",
    "        \"\"\"\n",
    "        self.weights -= self.alpha * new_grad\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Обучение модели\n",
    "        X - матрица объекты-признаки\n",
    "        y - вектор ответов\n",
    "        '''\n",
    "        k = X.shape[1] + 1\n",
    "        iter = 0\n",
    "        self.weights = np.array([random.uniform(-1 / k, 1 / k) for i in range(k)])\n",
    "        alpha_begin = self.alpha\n",
    "        for n in range(0, self.max_epoch):\n",
    "            new_epoch_generator = self.batch_generator(X, y, batch_size=self.batch_size)\n",
    "            for batch_num, new_batch in enumerate(new_epoch_generator):\n",
    "                X_batch = new_batch[0]\n",
    "                y_batch = new_batch[1]\n",
    "                batch_grad = self.calc_loss_grad(X_batch, y_batch)\n",
    "                batch_loss = self.calc_loss(X_batch, y_batch)\n",
    "                self.update_weights(batch_grad)\n",
    "                self.errors_log['iter'].append(iter)\n",
    "                self.errors_log['loss'].append(batch_loss)\n",
    "\n",
    "            self.alpha = alpha_begin / (iter + 1)\n",
    "            iter += 1\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Предсказание класса\n",
    "        X - матрица объекты-признаки\n",
    "        Не забудте тип модели (линейная или логистическая регрессия)!\n",
    "        '''\n",
    "\n",
    "        k = len(X)\n",
    "        list_added = []\n",
    "        for i in range(k):\n",
    "            list_added += [[1]]\n",
    "        X = np.concatenate((X, list_added), axis=1)\n",
    "        if self.model_type == 'lin_reg':\n",
    "            y_hat = [np.dot(X[i], self.weights) for i in range(X.shape[0])]\n",
    "        if self.model_type == 'log_reg':\n",
    "            y_hat = sigmoid(np.dot(X, self.weights))\n",
    "        return y_hat\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        k = len(X)\n",
    "        list_added = []\n",
    "        for i in range(k):\n",
    "            list_added += [[1]]\n",
    "        X = np.concatenate((X, list_added), axis=1)\n",
    "\n",
    "        if self.model_type == 'lin_reg':\n",
    "            return np.dot(X, self.weights)\n",
    "        if self.model_type == 'log_reg':\n",
    "            return sigmoid(np.dot(X, self.weights))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        a = [np.dot(np.concatenate((X[i], [1])), self.weights) for i in range(len(X))]\n",
    "        score = 0\n",
    "        a -= y\n",
    "        for i in a:\n",
    "            if (-0.5 < i < 0.5):\n",
    "                score += 1\n",
    "        score /= len(y)\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите обе регрессии на синтетических данных. \n",
    "\n",
    "\n",
    "Выведите полученные веса и нарисуйте разделяющую границу между классами (используйте только первых два веса для первых двух признаков X[:,0], X[:,1] для отображения в 2d пространство ).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf, name):\n",
    "    x = np.linspace(-5, 8, num=2)\n",
    "    y = -((clf.weights[0]*x+clf.weights[2])/clf.weights[1])\n",
    "    plt.plot(x, y, label='{}'.format(name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14321809 -0.16684393 -0.12262679]\n",
      "[ 0.5139306  -0.25260549 -1.51001735]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xce42290>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "C1 = np.array([[0., -0.8], [1.5, 0.8]])\n",
    "C2 = np.array([[1., -0.7], [2., 0.7]])\n",
    "gauss1 = np.dot(np.random.randn(200, 2) + np.array([5, 3]), C1)\n",
    "gauss2 = np.dot(np.random.randn(200, 2) + np.array([1.5, 0]), C2)\n",
    "\n",
    "X = np.vstack([gauss1, gauss2])\n",
    "y = np.r_[np.ones(200), np.zeros(200)]\n",
    "\n",
    "my_clf1 = MySGDClassifier(batch_generator=batch_generator, C=1000)\n",
    "my_clf1.fit(X, y)\n",
    "print(my_clf1.weights)\n",
    "plot_decision_boundary(my_clf1, 'lin_reg')\n",
    "\n",
    "my_clf2 = MySGDClassifier(batch_generator=batch_generator, C=10000, model_type='log_reg' )\n",
    "my_clf2.fit(X, y)\n",
    "print(my_clf2.weights)\n",
    "plot_decision_boundary(my_clf2, 'log_reg')\n",
    "\n",
    "# plot_decision_boundary(your_model)\n",
    "plt.scatter(X[:,0], X[:,1], c=y)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее будем анализировать Ваш алгоритм. \n",
    "Для этих заданий используйте датасет ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100000, n_features=10, \n",
    "                           n_informative=4, n_redundant=0, \n",
    "                           random_state=123, class_sep=1.0,\n",
    "                           n_clusters_per_class=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите сходимости обеих регрессией на этом датасете: изобразите график  функции потерь, усредненной по $N$ шагам градиентого спуска, для разных `alpha` (размеров шага). Разные `alpha` расположите на одном графике. \n",
    "\n",
    "$N$ можно брать 10, 50, 100 и т.д. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что Вы можете сказать про сходимость метода при различных `alpha`? Какое значение стоит выбирать для лучшей сходимости?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразите график среднего значения весов для обеих регрессий в зависимости от коеф. регуляризации С из `np.logspace(3, -3, 10)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Довольны ли Вы, насколько сильно уменьшились Ваши веса? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Боевое применение (3  балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте применим модель на итоговом проекте! Датасет сделаем точно таким же образом, как было показано в project_overview-2.ipynb\n",
    "\n",
    "Применим обе регрессии, подберем для них параметры и сравним качество. Может быть Вы еще одновременно с решением домашней работы подрастете на лидерборде!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28026\n"
     ]
    }
   ],
   "source": [
    "doc_to_title = {}\n",
    "with open('docs_titles.tsv') as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "        data = line.strip().split('\\t', 1)\n",
    "        doc_id = int(data[0])\n",
    "        if len(data) == 1:\n",
    "            title = ''\n",
    "        else:\n",
    "            title = data[1]\n",
    "        doc_to_title[doc_id] = title\n",
    "print (len(doc_to_title))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('train_groups.csv')\n",
    "traingroups_titledata = {}\n",
    "for i in range(len(train_data)):\n",
    "    new_doc = train_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    target = new_doc['target']\n",
    "    title = doc_to_title[doc_id]\n",
    "    if doc_group not in traingroups_titledata:\n",
    "        traingroups_titledata[doc_group] = []\n",
    "    traingroups_titledata[doc_group].append((doc_id, title, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11690, 15) (11690,) (11690,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_train = []\n",
    "X_train = []\n",
    "groups_train = []\n",
    "for new_group in traingroups_titledata:\n",
    "    docs = traingroups_titledata[new_group]\n",
    "    for k, (doc_id, title, target_id) in enumerate(docs):\n",
    "        y_train.append(target_id)\n",
    "        groups_train.append(new_group)\n",
    "        all_dist = []\n",
    "        words = set(title.strip().split())\n",
    "        for j in range(0, len(docs)):\n",
    "            if k == j:\n",
    "                continue\n",
    "            doc_id_j, title_j, target_j = docs[j]\n",
    "            words_j = set(title_j.strip().split())\n",
    "            all_dist.append(len(words.intersection(words_j)))\n",
    "        X_train.append(sorted(all_dist, reverse=True)[0:15]    )\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "groups_train = np.array(groups_train)\n",
    "print (X_train.shape, y_train.shape, groups_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите размер батча для обучения. Линейная модель не должна учиться дольше нескольких минут. \n",
    "\n",
    "Не забывайте использовать скейлер!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте данные на обучение и валидацию. Подберите параметры C, alpha, max_epoch, model_type на валидации (Вы же помните, как правильно в этой задаче делать валидацию?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С лучшими параметрами на валидации сделайте предсказание на тестовом множестве, отправьте его на проверку на платформу kaggle. Убедитесь, что Вы смогли побить public score первого бейзлайна. Если да, то Вы молодец!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Контрольные вопросы\n",
    "Постарайтесь максимально развернуто и честно ответить на вопросы. Они охватывают тему линейных моделей и скорее нужны преподавателям, чтобы понимать, что именно Вы усвоили плохо. Надеюсь, они подскажут, что именно в теме Вы не понимаете или наоборот порадают, что Вы все знаете ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Опишите основные, на Ваш взгляд,  отличия логистической регрессии от линейной регрессии. Почему, на ваш взгляд, задачу классификации решают логистической, а не линейной регрессией?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Как Вы думаете, для каких типов задач (объем данных, число признаков, типы признаков) стоит отдавать предпочтение линейным моделям?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Пусть на обучении мы имеем выборку размера $N$, число признаков $D$. Чему равна алгоритмическая сложность одного шага градиентного спуска? Cтохастического градиентного спуска?  Сложность предсказания на одном объекте?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В чем преимущества стохастического градиентного спуска (в том числе мини-батч) над обычным градиентным спуском? В чем его недостатки? Рассмотрите несколько аспектов $-$ скорость сходимости, необходимость загрузки всех данных в оперативную память, сложность вычисления одного шага."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Как Вы думаете, при обучении линейной модели с помощью SGD, ошибку на новом объекте стоит считать до итерации спуска на этом объекте или после? Почему Вы так думаете? Возможно, Вам будет интересно ознакомиться с http://hunch.net/~jl/projects/prediction_bounds/thesis/mathml/thesisse44.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Как Вы думаете, во времена такого бума нейронных сетей, остаются ли популярными линейные модели, или это уже пережиток прошлого? Почему Вы так думаете?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения линейных моделей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** ВАШ ОТЗЫВ ЗДЕСЬ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "402px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
