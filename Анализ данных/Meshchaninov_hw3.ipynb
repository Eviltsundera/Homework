{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 30 апреля 2018, 06:00   \n",
    "**Штраф за опоздание:** -2 балла после 06:00 30 апреля, -4 балла после 06:00 7 мая, -6 баллов после 06:00 14 мая, -8 баллов после 06:00 21 мая\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "#%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=0, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return 1 - np.sum((l_c ** 2) / l_s + (r_c ** 2) / r_s, axis=1) / ((l_s + r_s).flatten())\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        h_r = - np.sum((r_c / r_s) * np.log(r_c / r_s))\n",
    "        h_l = - np.sum((l_c / l_s) * np.log(l_c / l_s))\n",
    "        return (l_s * h_l + r_s * h_r) / (l_s + r_s)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        h_r = 1 - np.max(r_c / r_s, axis=1)\n",
    "        l_r = 1 - np.max(l_c / l_s, axis=1)\n",
    "        return (l_s * h_l + r_s * h_r) / (l_s + r_s)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.sqrt(n_feature))]\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.log2(n_feature) + 1)]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return range(n_feature)\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        '''\n",
    "        В начале сортируем массивы\n",
    "        После отбрасываем крайние элементы, так как по ним не пройдет разбиение\n",
    "        (position_changes)После создаем массив индексов, на которых меняются классы в массиве y\n",
    "        Если в y уже один класс, то выходим\n",
    "        (eq_el_count)Подсчитаем количество элементов между границами(граница - место, где меняется класс)\n",
    "        (one_hot_code)Составляем массив размерностью(кол-во изменений на кол-во классов),\n",
    "        1 помещаем туда на каком классе происходит изменение\n",
    "        (class_increments) Это массив на базе массива one_hot_code, \n",
    "        но в нем уже записаны элементы с учетом их количества, \n",
    "        расположенные между двумя возможными соседними точками разделения\n",
    "        (l_class_count)Массив на базе class_increments,\n",
    "        в котором уже записаны все элементы до точки разделения(по факту сумма на префиксах)\n",
    "        (r_class_count)То же что и l_class_count, но уже в обратном порядке(по факту сумма на суффиксах)\n",
    "        (l_sizes, r_sizes ) Размеры левых(правых) частей при разделении массива по определенной точке\n",
    "        Далее считаем ошибку и берем минимум\n",
    "    '''\n",
    "\n",
    "        x_sort, y_sort = self.__sort_samples(x, y)\n",
    "        class_number = self.num_class\n",
    "        bor = int(self.min_samples_split / 2 - 1)\n",
    "        y_split = y_sort\n",
    "        if bor:\n",
    "            y_split = y_sort[bor:-bor]\n",
    "        position_changes = np.where(y_split[:-1] != y_split[1:])[0] + (bor + 1)\n",
    "\n",
    "        if len(position_changes) == 0:\n",
    "            return np.inf, None\n",
    "\n",
    "        eq_el_count = position_changes - np.append([bor], position_changes[:-1])\n",
    "        one_hot_code = np.zeros((position_changes.shape[0], class_number))\n",
    "        one_hot_code[np.arange(position_changes.shape[0]), y_sort[position_changes - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + np.bincount(y_sort[:bor], minlength=class_number)\n",
    "\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)\n",
    "        r_class_count = np.bincount(y_sort, minlength=class_number) - l_class_count\n",
    "        l_sizes = position_changes.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = y_sort.shape[0] - l_sizes\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        return gs[idx], (x_sort[left_el_id - 1] + x_sort[left_el_id]) / 2.0\n",
    "\n",
    "    def Is_leaf(self, y, depth):\n",
    "        return (0 != self.max_depth <= depth) or \\\n",
    "               (self.sufficient_share <= np.bincount(y).argmax() / y.size) or \\\n",
    "               (y.size < self.min_samples_split)\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        if self.Is_leaf(y, depth):\n",
    "            self.tree[node_id] = [self.__class__.LEAF_TYPE, np.argmax(np.bincount(y))]\n",
    "        else:\n",
    "            thresholds = np.array([self.__find_threshold(x[:, i], y)\n",
    "                                   for i in self.get_feature_ids(x.shape[1])])\n",
    "            max_feature = np.argmin(thresholds[:, 0])\n",
    "            max_threshold = thresholds[max_feature, 1]\n",
    "\n",
    "            if max_threshold == None:\n",
    "                self.tree[node_id] = [self.__class__.LEAF_TYPE, np.argmax(np.bincount(y))]\n",
    "            else:\n",
    "                l_x, r_x, l_y, r_y = self.__div_samples(x, y, max_feature, max_threshold)\n",
    "\n",
    "                if (l_x.size == 0) or (r_x.size == 0):\n",
    "                    self.tree[node_id] = [self.__class__.LEAF_TYPE, np.argmax(np.bincount(y))]\n",
    "                else:\n",
    "                    self.tree[node_id] = [self.__class__.NON_LEAF_TYPE, max_feature, max_threshold]\n",
    "                    self.__fit_node(l_x, l_y, 2 * node_id + 1, depth + 1)\n",
    "                    self.__fit_node(r_x, r_y, 2 * node_id + 2, depth + 1)\n",
    "                    l_s = np.array(l_y.size)\n",
    "                    r_s = np.array(r_y.size)\n",
    "                    if self.G_function == self.__gini:\n",
    "                        c = 1 - np.sum((np.unique(y, return_counts=True)[1] / y.size) ** 2)\n",
    "                        l_c = 1 - np.sum((np.unique(l_y, return_counts=True)[1] / l_y.size) ** 2)\n",
    "                        r_c = 1 - np.sum((np.unique(r_y, return_counts=True)[1] / r_y.size) ** 2)\n",
    "                        self.feature_importances_[max_feature] += (y.size * c -\n",
    "                                                                   l_y.size * l_c - r_y.size * r_c)\n",
    "                    if self.G_function == self.__entropy:\n",
    "                        c = -np.sum(np.unique(y, return_counts=True)[1] *\n",
    "                                    np.log2(np.unique(y, return_counts=True)[1])) / y.size\n",
    "                        l_c = -np.sum(np.unique(l_y, return_counts=True)[1] *\n",
    "                                      np.log2(np.unique(l_y, return_counts=True)[1])) / l_y.size\n",
    "                        r_c = -np.sum(np.unique(r_y, return_counts=True)[1] *\n",
    "                                      np.log2(np.unique(r_y, return_counts=True)[1])) / r_y.size\n",
    "                        self.feature_importances_[best_id] += y.size * c - l_y.size * l_c - l_y.size * r_c\n",
    "                    if self.G_function == self.__misclass:\n",
    "                        c = 1 - np.max(np.sum(np.unique(y, return_counts=True)[1])) / y.size\n",
    "                        c_l = 1 - np.max(np.sum(np.unique(l_y, return_counts=True)[1])) / y.size\n",
    "                        c_r = 1 - np.max(np.sum(np.unique(r_y, return_counts=True)[1])) / y.size\n",
    "                        self.feature_importances_[best_id] += y.size * c - l_y.size * l_c - r_y.size * r_c\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        y = y.astype('int64')\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(len(x[0]))\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        self.feature_importances_ /= np.sum(self.feature_importances_)\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 1, 0, 2, 1, 2, 2, 1, 0, 0, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1,\n",
       "       0, 1, 2, 2, 0, 1, 0, 2, 1, 2, 0, 2, 0, 0, 2, 1, 1, 2, 1, 0, 1, 2,\n",
       "       1, 2, 1, 0, 1, 0, 2, 0, 1, 1, 0, 1, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2,\n",
       "       1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 1, 0, 0, 2, 2,\n",
       "       1, 2, 2, 0, 0, 2, 2, 0, 1, 0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 0, 1, 2, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 2, 0, 0, 1, 0, 2, 1, 0, 0, 0, 2,\n",
       "       2, 2, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.97 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8885003885003885"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8885003885003885"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Speed Dating Data.csv', encoding='ansi')\n",
    "for i in df.columns:\n",
    "    if type(df[i][0]) not in [np.float64, np.int64, float]:\n",
    "        df.drop(i, axis=1, inplace=True)\n",
    "for i in df.columns:\n",
    "    if df[i].isnull().sum() > 500:\n",
    "        df.drop(i, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(-10000)\n",
    "df.drop('id', axis=1)\n",
    "y = df.loc[:, 'gender'].values\n",
    "X = df.drop('gender', axis=1).iloc[:, :].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 122 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 859 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9880619128006781"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9880606881773744"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_features</th>\n",
       "      <th>sklearn_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   my_features  sklearn_features\n",
       "0            3                35\n",
       "1           45                45\n",
       "2           66                60\n",
       "3           60                53\n",
       "4           53                 0\n",
       "5            9                66\n",
       "6            0                 9\n",
       "7           62                62\n",
       "8           15                15\n",
       "9           56                56"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({})\n",
    "data['my_features'] = np.argsort(my_clf.feature_importances_)[-10:]\n",
    "data['sklearn_features'] = np.argsort(clf.feature_importances_)[-10:]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_features': ['log2', 'sqrt', None], 'min_samples_split': range(2, 15), 'max_depth': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], 'criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estim = RandomForestClassifier(n_estimators=10)\n",
    "param_grid = {\n",
    "              'max_features': ['log2', 'sqrt', None],\n",
    "              'min_samples_split': range(2, 15),\n",
    "              'max_depth': [i for i in range(5, 20)],\n",
    "              'criterion': ['gini', 'entropy']\n",
    "            }\n",
    "grid_cv = GridSearchCV(estim, param_grid)\n",
    "grid_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=6,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_split': 6}"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
